{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8dd7df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "210ca08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prajakta B\\AppData\\Local\\Temp\\ipykernel_10720\\885378504.py:4: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_features = pd.read_csv(\"C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom.data\",\n",
      "C:\\Users\\Prajakta B\\AppData\\Local\\Temp\\ipykernel_10720\\885378504.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_labels = pd.read_csv(\"C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom_labels.data\",\n"
     ]
    }
   ],
   "source": [
    "#Read Data from soruces\n",
    "\n",
    "# Read the sensor feature file (590 columns, no header)\n",
    "df_features = pd.read_csv(\"C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom.data\",\n",
    "                          delim_whitespace=True,  # or sep=' '\n",
    "                          header=None)\n",
    "\n",
    "# Read the labels file (two columns: label and timestamp)\n",
    "df_labels = pd.read_csv(\"C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom_labels.data\",\n",
    "                        delim_whitespace=True,\n",
    "                        header=None)\n",
    "\n",
    "# df_features.head()\n",
    "# df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d08a3214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prajakta B\\AppData\\Local\\Temp\\ipykernel_10720\\4161458270.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  secom_data = pd.read_csv('C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom.data', delim_whitespace=True, header=None)\n",
      "C:\\Users\\Prajakta B\\AppData\\Local\\Temp\\ipykernel_10720\\4161458270.py:7: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  labels = pd.read_csv('C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom_labels.data', delim_whitespace=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "#Combining data and creating proper structure of table\n",
    "\n",
    "\n",
    "# Loading dataset \n",
    "try:\n",
    "    secom_data = pd.read_csv('C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom.data', delim_whitespace=True, header=None)\n",
    "    labels = pd.read_csv('C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom_labels.data', delim_whitespace=True, header=None)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please verify file paths and names.\")\n",
    "    exit()\n",
    "    \n",
    "# Rename columns like feature_1,2.. target_1,2..\n",
    "num_sensors = secom_data.shape[1]  # Number of sensor columns\n",
    "new_columns = [f'feature_{i+1}' for i in range(num_sensors)] \n",
    "secom_data.columns = new_columns\n",
    "\n",
    "labels.columns = [\"is_faulty\", \"date_time\"]\n",
    "\n",
    "df = pd.concat([\n",
    "          secom_data, labels\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e531705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency distribution BEFORE sampling:\n",
      "           proportion\n",
      "is_faulty            \n",
      "-1           0.933631\n",
      " 1           0.066369\n",
      "           count\n",
      "is_faulty       \n",
      "-1          1463\n",
      " 1           104\n",
      "----------------------------------------\n",
      "Frequency distribution in TRAIN set:\n",
      "           proportion\n",
      "is_faulty            \n",
      "-1           0.933759\n",
      " 1           0.066241\n",
      "           count\n",
      "is_faulty       \n",
      "-1          1170\n",
      " 1            83\n",
      "----------------------------------------\n",
      "Frequency distribution in TEST set:\n",
      "           proportion\n",
      "is_faulty            \n",
      "-1           0.933121\n",
      " 1           0.066879\n",
      "           count\n",
      "is_faulty       \n",
      "-1           293\n",
      " 1            21\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test & train dataset split with stratified sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_colms = [col for col in df.columns if col not in ['is_faulty']]\n",
    "# Features: all columns starting with 'feature_'\n",
    "X = df[feature_colms]\n",
    "\n",
    "# Target: 'is_faulty'\n",
    "y = df['is_faulty']\n",
    "\n",
    "# Show frequency distribution before sampling\n",
    "print(\"Frequency distribution BEFORE sampling:\")\n",
    "print(y.value_counts(normalize=True).rename('proportion').to_frame())\n",
    "print(y.value_counts().rename('count').to_frame())\n",
    "print('-' * 40)\n",
    "\n",
    "# Stratified train-test split (67% train, 33% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,        # 20% test, 80% train\n",
    "    random_state=42,       # seed value\n",
    "    stratify=y             # Stratified split based on is_faulty\n",
    ")\n",
    "\n",
    "\n",
    "# Show frequency distribution in train set\n",
    "print(\"Frequency distribution in TRAIN set:\")\n",
    "print(y_train.value_counts(normalize=True).rename('proportion').to_frame())\n",
    "print(y_train.value_counts().rename('count').to_frame())\n",
    "print('-' * 40)\n",
    "\n",
    "# Show frequency distribution in test set\n",
    "print(\"Frequency distribution in TEST set:\")\n",
    "print(y_test.value_counts(normalize=True).rename('proportion').to_frame())\n",
    "print(y_test.value_counts().rename('count').to_frame())\n",
    "print('-' * 40)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "train_df_clean = pd.concat([X_train, y_train], axis=1)\n",
    "# Display datasets\n",
    "# train_df\n",
    "# test_df \n",
    "# train_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ea63c472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial number of columns: 592\n",
      "Number of zero-volatility columns removed: 116\n",
      "Final number of columns: 476\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning in train dataset train_df_clean\n",
    "# zero volatality columns\n",
    "\n",
    "# Count initial columns (including target)\n",
    "initial_col_count = train_df_clean.shape[1]\n",
    "print(f\"\\nInitial number of columns: {initial_col_count}\")\n",
    "\n",
    "# Identify feature columns (exclude target)\n",
    "feature_cols = [col for col in df.columns if col not in ['is_faulty', 'date_time']]\n",
    "\n",
    "# Find zero-volatility columns (std = 0)\n",
    "stds = train_df_clean[feature_cols].std()\n",
    "zero_vol_cols = stds[stds == 0].index.tolist()\n",
    "\n",
    "# Remove zero-volatility columns\n",
    "train_df_clean = train_df_clean.drop(columns=zero_vol_cols)\n",
    "\n",
    "# Count final columns (including target)\n",
    "final_col_count = train_df_clean.shape[1]\n",
    "print(f\"Number of zero-volatility columns removed: {len(zero_vol_cols)}\")\n",
    "print(f\"Final number of columns: {final_col_count}\")\n",
    "# print(train_df_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9fadd52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns before removal: 476\n",
      "Number of columns with >50% missing values: 32\n",
      "Columns to drop due to missing values >50%:\n",
      "['feature_73', 'feature_74', 'feature_86', 'feature_110', 'feature_111', 'feature_112', 'feature_113', 'feature_158', 'feature_159', 'feature_221', 'feature_245', 'feature_246', 'feature_247', 'feature_248', 'feature_293', 'feature_294', 'feature_346', 'feature_347', 'feature_359', 'feature_383', 'feature_384', 'feature_385', 'feature_386', 'feature_493', 'feature_517', 'feature_518', 'feature_519', 'feature_520', 'feature_579', 'feature_580', 'feature_581', 'feature_582']\n",
      "Number of columns after removal: 444\n",
      "Number of columns removed: 32\n"
     ]
    }
   ],
   "source": [
    "# missing values column dropping\n",
    "# Count columns before removal\n",
    "before_cols = train_df_clean.shape[1]\n",
    "print(f\"Number of columns before removal: {before_cols}\")\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "missing_percent = train_df_clean.isnull().mean()\n",
    "\n",
    "\n",
    "# Identify columns with more than 50% missing values\n",
    "cols_to_drop = missing_percent[missing_percent > 0.44].index.tolist()\n",
    "\n",
    "print(f\"Number of columns with >50% missing values: {len(cols_to_drop)}\")\n",
    "print(\"Columns to drop due to missing values >50%:\")\n",
    "print(cols_to_drop)\n",
    "\n",
    "# Drop these columns\n",
    "train_df_clean = train_df_clean.drop(columns=cols_to_drop)\n",
    "\n",
    "# Count columns after removal\n",
    "after_cols = train_df_clean.shape[1]\n",
    "print(f\"Number of columns after removal: {after_cols}\")\n",
    "print(f\"Number of columns removed: {before_cols - after_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8f3fcf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle missing values with KNN\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# # Identify feature columns (exclude target)\n",
    "# feature_cols = [col for col in train_df_clean.columns if col not in ['is_faulty', 'date_time']]\n",
    "\n",
    "# # Select only numeric columns among features\n",
    "# numeric_feature_cols = train_df_clean[feature_cols].select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# # Store 'is_faulty' and 'date_time' separately\n",
    "# meta_cols = train_df_clean[['is_faulty', 'date_time']].copy()\n",
    "\n",
    "# # Apply KNN imputer only to numeric feature columns\n",
    "# imputer = KNNImputer(n_neighbors=3)\n",
    "# imputed_features = pd.DataFrame(\n",
    "#     imputer.fit_transform(train_df_clean[numeric_feature_cols]),\n",
    "#     columns=numeric_feature_cols,\n",
    "#     index=train_df_clean.index\n",
    "# )\n",
    "\n",
    "# # If you have any non-numeric feature columns, add them back (if needed)\n",
    "# non_numeric_cols = [col for col in feature_cols if col not in numeric_feature_cols]\n",
    "# imputed_df = pd.concat([imputed_features, train_df_clean[non_numeric_cols]], axis=1)\n",
    "\n",
    "# # Append 'is_faulty' and 'date_time' columns back\n",
    "# train_df_clean = pd.concat([imputed_df, meta_cols], axis=1)\n",
    "\n",
    "# print(train_df_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High Correlation columns\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initial column count\n",
    "initial_cols = train_df_clean.shape[1]\n",
    "\n",
    "# Identify feature columns (exclude target and date)\n",
    "feature_cols = [col for col in train_df_clean.columns if col not in ['is_faulty', 'date_time']]\n",
    "\n",
    "# Ensure all features are numeric \n",
    "X = train_df_clean[feature_cols]\n",
    "if X.select_dtypes(include=['object', 'category']).shape[1] > 0:\n",
    "    X = pd.get_dummies(X)\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Compute MI scores\n",
    "y = train_df_clean['is_faulty'].values\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "mi_series = pd.Series(mi_scores, index=X.columns)\n",
    "\n",
    "# Compute correlation matrix and its upper triangle\n",
    "corr_matrix = X.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "threshold = 0.8\n",
    "to_drop = set()\n",
    "\n",
    "# For each pair of highly correlated columns, drop the one with lower MI\n",
    "for col in upper.columns:\n",
    "    for row in upper.index:\n",
    "        if pd.notnull(upper.loc[row, col]) and upper.loc[row, col] > threshold:\n",
    "            if mi_series[col] < mi_series[row]:\n",
    "                to_drop.add(col)\n",
    "            else:\n",
    "                to_drop.add(row)\n",
    "\n",
    "# Drop the selected columns\n",
    "train_df_clean = train_df_clean.drop(columns=list(to_drop))\n",
    "\n",
    "# Print results\n",
    "print(f\"Columns dropped due to high correlation: {len(to_drop)}\")\n",
    "print(\"\\nList of dropped columns:\")\n",
    "print(list(to_drop))\n",
    "\n",
    "# Final count\n",
    "final_cols = train_df_clean.shape[1]\n",
    "print(f\"\\nInitial columns: {initial_cols}\")\n",
    "print(f\"Final columns: {final_cols}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2080f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 sigma \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Select numeric columns, excluding target and date\n",
    "numeric_cols = train_df_clean.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['is_faulty', 'date_time']]\n",
    "\n",
    "# Compute z-scores for all numeric columns\n",
    "z_scores = stats.zscore(train_df_clean[numeric_cols], nan_policy='omit')\n",
    "\n",
    "# Make a copy to cap outliers\n",
    "# train_df_capped = train_df_clean.copy()\n",
    "\n",
    "# # Capping function using z-scores\n",
    "# for idx, col in enumerate(numeric_cols):\n",
    "#     col_mean = train_df_clean[col].mean()\n",
    "#     col_std = train_df_clean[col].std()\n",
    "#     lower = col_mean - 3 * col_std\n",
    "#     upper = col_mean + 3 * col_std\n",
    "\n",
    "#     # Find outliers using z-score\n",
    "#     outliers_high = z_scores[:, idx] > 3\n",
    "#     outliers_low = z_scores[:, idx] < -3\n",
    "\n",
    "#     # Cap high outliers\n",
    "#     train_df_capped.loc[outliers_high, col] = upper\n",
    "#     # Cap low outliers\n",
    "#     train_df_capped.loc[outliers_low, col] = lower\n",
    "\n",
    "# print(\"Capping done using 3-sigma rule with z-scores.\")\n",
    "\n",
    "# # Optionally, show how many values were capped per column\n",
    "# capped_counts = {}\n",
    "# for idx, col in enumerate(numeric_cols):\n",
    "#     capped_counts[col] = ((z_scores[:, idx] > 3) | (z_scores[:, idx] < -3)).sum()\n",
    "\n",
    "# print(\"Number of capped values per column (3-sigma rule):\")\n",
    "# print({k: v for k, v in capped_counts.items() if v > 0})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2663f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 sigma\n",
    "# Select numeric columns, excluding target and date if needed\n",
    "# numeric_cols = train_df_clean.select_dtypes(include=[np.number]).columns\n",
    "# numeric_cols = [col for col in numeric_cols if col not in ['is_faulty', 'date_time']]\n",
    "\n",
    "# outlier_columns = []\n",
    "\n",
    "# for col in numeric_cols:\n",
    "#     data = train_df_clean[col]\n",
    "#     mean = data.mean()\n",
    "#     std = data.std()\n",
    "#     lower = mean - 4 * std\n",
    "#     upper = mean + 4 * std\n",
    "#     outliers = (data < lower) | (data > upper)\n",
    "#     if outliers.any():\n",
    "#         outlier_columns.append(col)\n",
    "        \n",
    "\n",
    "\n",
    "# print(\"Columns containing outliers (3-sigma rule):\")\n",
    "# print(outlier_columns)\n",
    "# print(\"count:\")\n",
    "# print(len(outlier_columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0f9857c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_1  feature_2  feature_3  feature_4  feature_5  feature_7  \\\n",
      "1198    3075.32    2491.07  2185.1000  1201.0491     0.7821   105.8489   \n",
      "436     3071.58    2489.47  2217.3777  1425.1041     1.7585   106.2556   \n",
      "635     3017.53    2524.09  2201.0667   880.2317     1.4148   106.5478   \n",
      "996     2901.62    2569.45  2223.9000  1745.3724     1.9974    96.7567   \n",
      "782     2982.59    2466.86  2117.5889   894.0996     1.4330   106.4944   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "180     3058.89    2504.38  2221.9444  1551.6947     1.5296    99.2678   \n",
      "365     2988.92    2460.91  2178.0778   941.9524     0.8039   104.0167   \n",
      "1420    2975.74    2517.35  2162.5556  1041.0369     1.4305   100.4111   \n",
      "113     2928.16    2523.21  2210.6111  1184.6481     1.2577   102.9356   \n",
      "470     2929.84    2504.50  2183.3111  1588.5090     1.6269   102.8467   \n",
      "\n",
      "      feature_8  feature_9  feature_10  feature_11  ...  feature_583  \\\n",
      "1198     0.1208     1.4002     -0.0151     -0.0006  ...       0.4974   \n",
      "436      0.1200     1.5270      0.0066     -0.0124  ...       0.5004   \n",
      "635      0.1211     1.3720     -0.0005      0.0052  ...       0.4998   \n",
      "996      0.1241     1.5950     -0.0163      0.0061  ...       0.5004   \n",
      "782      0.1253     1.4418     -0.0096      0.0006  ...       0.4986   \n",
      "...         ...        ...         ...         ...  ...          ...   \n",
      "180      0.1222     1.4068      0.0057      0.0033  ...       0.5018   \n",
      "365      0.1229     1.5829     -0.0278     -0.0324  ...       0.4976   \n",
      "1420     0.1238     1.4968     -0.0201     -0.0060  ...       0.4994   \n",
      "113      0.1201     1.4453     -0.0126      0.0152  ...       0.5016   \n",
      "470      0.1248     1.5545     -0.0370     -0.0001  ...       0.4985   \n",
      "\n",
      "      feature_584  feature_585  feature_586  feature_587  feature_588  \\\n",
      "1198       0.0128       0.0033       2.5767       0.0223       0.0105   \n",
      "436        0.0316       0.0066       6.3183       0.0329       0.0055   \n",
      "635        0.0097       0.0026       1.9495       0.0328       0.0235   \n",
      "996        0.0174       0.0034       3.4771       0.0200       0.0205   \n",
      "782        0.0172       0.0038       3.4561       0.0373       0.0079   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "180        0.0460       0.0097       9.1677      -0.0012       0.0220   \n",
      "365        0.0148       0.0032       2.9645       0.0291       0.0135   \n",
      "1420       0.0115       0.0033       2.3077       0.0299       0.0071   \n",
      "113        0.0160       0.0035       3.1882       0.0049       0.0144   \n",
      "470        0.0150       0.0045       3.0151       0.0193       0.0122   \n",
      "\n",
      "      feature_589  feature_590  is_faulty            date_time  \n",
      "1198       0.0034      47.0690         -1  30/09/2008 15:26:00  \n",
      "436        0.0022      16.6695         -1  23/08/2008 05:58:00  \n",
      "635        0.0068      71.5333         -1  01/09/2008 20:51:00  \n",
      "996        0.0061     102.5241         -1  21/09/2008 19:19:00  \n",
      "782        0.0030      21.0599         -1  11/09/2008 07:43:00  \n",
      "...           ...          ...        ...                  ...  \n",
      "180        0.0072       0.0000          1  10/08/2008 06:00:00  \n",
      "365        0.0045      46.4165         -1  21/08/2008 15:32:00  \n",
      "1420       0.0020      23.6431         -1  08/10/2008 10:37:00  \n",
      "113        0.0047     293.2614         -1  05/08/2008 06:21:00  \n",
      "470        0.0040      63.0838         -1  28/08/2008 07:40:00  \n",
      "\n",
      "[1253 rows x 444 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Handle missing values with KNN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Identify feature columns (exclude target)\n",
    "feature_cols = [col for col in train_df_clean.columns if col not in ['is_faulty', 'date_time']]\n",
    "\n",
    "# Select only numeric columns among features\n",
    "numeric_feature_cols = train_df_clean[feature_cols].select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Store 'is_faulty' and 'date_time' separately\n",
    "meta_cols = train_df_clean[['is_faulty', 'date_time']].copy()\n",
    "\n",
    "# Apply KNN imputer only to numeric feature columns\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_features = pd.DataFrame(\n",
    "    imputer.fit_transform(train_df_clean[numeric_feature_cols]),\n",
    "    columns=numeric_feature_cols,\n",
    "    index=train_df_clean.index\n",
    ")\n",
    "\n",
    "# If you have any non-numeric feature columns, add them back (if needed)\n",
    "non_numeric_cols = [col for col in feature_cols if col not in numeric_feature_cols]\n",
    "imputed_df = pd.concat([imputed_features, train_df_clean[non_numeric_cols]], axis=1)\n",
    "\n",
    "# Append 'is_faulty' and 'date_time' columns back\n",
    "train_df_clean = pd.concat([imputed_df, meta_cols], axis=1)\n",
    "\n",
    "print(train_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "481c7a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression ---\n",
      "Cross-validated F1 (macro) Scores: [0.55432373 0.6097809  0.57757296 0.57281065 0.56175758]\n",
      "Mean CV F1 (macro): 0.5752\n",
      "Test Set F1 (macro): 0.5899\n",
      "Test Set Accuracy: 0.896414342629482\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.94      0.94       234\n",
      "           1       0.24      0.24      0.24        17\n",
      "\n",
      "    accuracy                           0.90       251\n",
      "   macro avg       0.59      0.59      0.59       251\n",
      "weighted avg       0.90      0.90      0.90       251\n",
      "\n",
      "\n",
      "--- Random Forest ---\n",
      "Cross-validated F1 (macro) Scores: [0.48329049 0.48195876 0.48186528 0.48320413 0.48320413]\n",
      "Mean CV F1 (macro): 0.4827\n",
      "Test Set F1 (macro): 0.4825\n",
      "Test Set Accuracy: 0.9322709163346613\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      1.00      0.96       234\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.93       251\n",
      "   macro avg       0.47      0.50      0.48       251\n",
      "weighted avg       0.87      0.93      0.90       251\n",
      "\n",
      "\n",
      "--- SVM (RBF kernel) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prajakta B\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Prajakta B\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Prajakta B\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1 (macro) Scores: [0.48329049 0.48195876 0.48320413 0.48320413 0.48320413]\n",
      "Mean CV F1 (macro): 0.4830\n",
      "Test Set F1 (macro): 0.4825\n",
      "Test Set Accuracy: 0.9322709163346613\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      1.00      0.96       234\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.93       251\n",
      "   macro avg       0.47      0.50      0.48       251\n",
      "weighted avg       0.87      0.93      0.90       251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prajakta B\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Prajakta B\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Prajakta B\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Modelling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# --- Data Preparation (as in your code) ---\n",
    "# Identify feature columns (exclude target)\n",
    "feature_cols = [col for col in train_df_clean.columns if col not in ['is_faulty', 'date_time']]\n",
    "\n",
    "# Select only numeric columns among features\n",
    "numeric_feature_cols = train_df_clean[feature_cols].select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Store 'is_faulty' and 'date_time' separately\n",
    "meta_cols = train_df_clean[['is_faulty', 'date_time']].copy()\n",
    "\n",
    "# Apply KNN imputer only to numeric feature columns\n",
    "# imputer = KNNImputer(n_neighbors=5)\n",
    "# imputed_features = pd.DataFrame(\n",
    "#     imputer.fit_transform(train_df_clean[numeric_feature_cols]),\n",
    "#     columns=numeric_feature_cols,\n",
    "#     index=train_df_clean.index\n",
    "# )\n",
    "\n",
    "# If you have any non-numeric feature columns, add them back (if needed)\n",
    "non_numeric_cols = [col for col in feature_cols if col not in numeric_feature_cols]\n",
    "imputed_df = pd.concat([imputed_features, train_df_clean[non_numeric_cols]], axis=1)\n",
    "\n",
    "# Append 'is_faulty' and 'date_time' columns back\n",
    "train_df_clean = pd.concat([imputed_df, meta_cols], axis=1)\n",
    "\n",
    "# --- Modeling Setup ---\n",
    "X = train_df_clean[numeric_feature_cols]\n",
    "y = train_df_clean['is_faulty']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Define Models ---\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000, solver='lbfgs'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF kernel)': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "# --- Train, Cross-Validate, and Evaluate Each Model ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    # Cross-validation with F1 score (macro average for imbalanced classes)\n",
    "    cv_f1 = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='f1_macro')\n",
    "    print(f\"Cross-validated F1 (macro) Scores: {cv_f1}\")\n",
    "    print(f\"Mean CV F1 (macro): {cv_f1.mean():.4f}\")\n",
    "\n",
    "    # Fit on training data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    # F1 score on test set\n",
    "    test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Test Set F1 (macro):\", f\"{test_f1:.4f}\")\n",
    "    print(\"Test Set Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "35aacfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_final = train_df_clean[\"is_faulty\"]\n",
    "# X_train_final = train_df_clean.drop(columns=[\"is_faulty\",\"date_time\"])\n",
    "# # X_test_final = X_test_imputed.drop(columns=high_corr_to_drop)\n",
    "\n",
    "# # y_train_arr = y_train.drop(columns='date_time')\n",
    "# y_train_final = y_train_final.to_numpy()\n",
    "\n",
    "# # Numerical Columns\n",
    "# numerical_columns = X_train_final.columns.to_list()\n",
    "\n",
    "# # Numerical Preprocessing Pipeline: Impute missing values with median and scale\n",
    "# numerical_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         #('imputer', SimpleImputer(strategy='median')),\n",
    "#         ('scaler', MinMaxScaler())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Combine into a Column Transformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num_pipeline', numerical_pipeline, numerical_columns)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # %%\n",
    "# # Define Models\n",
    "# models = {\n",
    "#     'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=-1),\n",
    "#     'Random Forest': RandomForestClassifier(class_weight='balanced', n_jobs=-1),\n",
    "#     'SVM': SVC(class_weight='balanced')\n",
    "# }\n",
    "\n",
    "# # Define scoring metrics for imbalanced data (focus on class 1 = failure)\n",
    "# scoring = {\n",
    "#     'precision': make_scorer(precision_score, average='binary', pos_label=1),\n",
    "#     'recall': make_scorer(recall_score, average='binary', pos_label=1),\n",
    "#     'f1': make_scorer(f1_score, average='binary', pos_label=1)\n",
    "# }\n",
    "\n",
    "# # Stratified cross-validation\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Run CV for each model\n",
    "# results = []\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     pipeline = Pipeline(steps=[\n",
    "#         ('preprocessing', preprocessor),\n",
    "#         ('classifier', model)\n",
    "#     ])\n",
    "\n",
    "#     print(f\"Training {model_name}...\")\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     y_pred = cross_val_predict(pipeline, X_train_final, y_train_final, cv=cv)\n",
    "#     execution_time = round(time.time() - start_time, 2)\n",
    "    \n",
    "#     # Compute Metrics (still targeting Fail class = 1 as positive class)\n",
    "#     precision = round(precision_score(y_train_final, y_pred, pos_label=1), 4)\n",
    "#     recall = round(recall_score(y_train_final, y_pred, pos_label=1), 4)\n",
    "#     f1 = round(f1_score(y_train_final, y_pred, pos_label=1), 4)\n",
    "\n",
    "#     # Standard format: [[TN, FP], [FN, TP]]\n",
    "#     # Negative class: -1 (Pass), Positive class: 1 (Fail)\n",
    "#     cm_raw = confusion_matrix(y_train_final, y_pred, labels=[-1, 1])\n",
    "#     tn, fp = cm_raw[0]\n",
    "#     fn, tp = cm_raw[1]\n",
    "#     cm = np.array([[tn, fp],\n",
    "#                    [fn, tp]])\n",
    "\n",
    "\n",
    "#     results.append({\n",
    "#         'Model': model_name,\n",
    "#         'Precision': precision,\n",
    "#         'Recall': recall,\n",
    "#         'F1 Score': f1,\n",
    "#         'Confusion Matrix': cm,\n",
    "#         'Execution Time (s)': execution_time\n",
    "#     })\n",
    "\n",
    "# results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)\n",
    "# print(\"\\nðŸ“ˆ Model Comparison:\\n\")\n",
    "# print(results_df)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
