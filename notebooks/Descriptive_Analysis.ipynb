{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5377a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prajakta B\\AppData\\Local\\Temp\\ipykernel_19756\\2940576997.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_features = pd.read_csv(\"C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom.data\",\n",
      "C:\\Users\\Prajakta B\\AppData\\Local\\Temp\\ipykernel_19756\\2940576997.py:11: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_labels = pd.read_csv(\"C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom_labels.data\",\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19/07/2008 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 15:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                    1\n",
       "0 -1  19/07/2008 11:55:00\n",
       "1 -1  19/07/2008 12:32:00\n",
       "2  1  19/07/2008 13:17:00\n",
       "3 -1  19/07/2008 14:43:00\n",
       "4 -1  19/07/2008 15:22:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Data from \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the sensor feature file (590 columns, no header)\n",
    "df_features = pd.read_csv(\"C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom.data\",\n",
    "                          delim_whitespace=True,  # or sep=' '\n",
    "                          header=None)\n",
    "\n",
    "# Read the labels file (two columns: label and timestamp)\n",
    "df_labels = pd.read_csv(\"C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom_labels.data\",\n",
    "                        delim_whitespace=True,\n",
    "                        header=None)\n",
    "\n",
    "df_features.head()\n",
    "df_labels.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "121fa0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prajakta B\\AppData\\Local\\Temp\\ipykernel_19756\\3233132748.py:7: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  secom_data = pd.read_csv('C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom.data', delim_whitespace=True, header=None)\n",
      "C:\\Users\\Prajakta B\\AppData\\Local\\Temp\\ipykernel_19756\\3233132748.py:8: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  labels = pd.read_csv('C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom_labels.data', delim_whitespace=True, header=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_583</th>\n",
       "      <th>feature_584</th>\n",
       "      <th>feature_585</th>\n",
       "      <th>feature_586</th>\n",
       "      <th>feature_587</th>\n",
       "      <th>feature_588</th>\n",
       "      <th>feature_589</th>\n",
       "      <th>feature_590</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "      <td>19/07/2008 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 15:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "      <td>16/10/2008 15:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "      <td>16/10/2008 20:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>-1</td>\n",
       "      <td>17/10/2008 05:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>-1</td>\n",
       "      <td>17/10/2008 06:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>-1</td>\n",
       "      <td>17/10/2008 06:07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows Ã— 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0       3030.93    2564.00  2187.7333  1411.1265     1.3602      100.0   \n",
       "1       3095.78    2465.14  2230.4222  1463.6606     0.8294      100.0   \n",
       "2       2932.61    2559.94  2186.4111  1698.0172     1.5102      100.0   \n",
       "3       2988.72    2479.90  2199.0333   909.7926     1.3204      100.0   \n",
       "4       3032.24    2502.87  2233.3667  1326.5200     1.5334      100.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1562    2899.41    2464.36  2179.7333  3085.3781     1.4843      100.0   \n",
       "1563    3052.31    2522.55  2198.5667  1124.6595     0.8763      100.0   \n",
       "1564    2978.81    2379.78  2206.3000  1110.4967     0.8236      100.0   \n",
       "1565    2894.92    2532.01  2177.0333  1183.7287     1.5726      100.0   \n",
       "1566    2944.92    2450.76  2195.4444  2914.1792     1.5978      100.0   \n",
       "\n",
       "      feature_7  feature_8  feature_9  feature_10  ...  feature_583  \\\n",
       "0       97.6133     0.1242     1.5005      0.0162  ...       0.5005   \n",
       "1      102.3433     0.1247     1.4966     -0.0005  ...       0.5019   \n",
       "2       95.4878     0.1241     1.4436      0.0041  ...       0.4958   \n",
       "3      104.2367     0.1217     1.4882     -0.0124  ...       0.4990   \n",
       "4      100.3967     0.1235     1.5031     -0.0031  ...       0.4800   \n",
       "...         ...        ...        ...         ...  ...          ...   \n",
       "1562    82.2467     0.1248     1.3424     -0.0045  ...       0.4988   \n",
       "1563    98.4689     0.1205     1.4333     -0.0061  ...       0.4975   \n",
       "1564    99.4122     0.1208        NaN         NaN  ...       0.4987   \n",
       "1565    98.7978     0.1213     1.4622     -0.0072  ...       0.5004   \n",
       "1566    85.1011     0.1235        NaN         NaN  ...       0.4987   \n",
       "\n",
       "      feature_584  feature_585  feature_586  feature_587  feature_588  \\\n",
       "0          0.0118       0.0035       2.3630          NaN          NaN   \n",
       "1          0.0223       0.0055       4.4447       0.0096       0.0201   \n",
       "2          0.0157       0.0039       3.1745       0.0584       0.0484   \n",
       "3          0.0103       0.0025       2.0544       0.0202       0.0149   \n",
       "4          0.4766       0.1045      99.3032       0.0202       0.0149   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1562       0.0143       0.0039       2.8669       0.0068       0.0138   \n",
       "1563       0.0131       0.0036       2.6238       0.0068       0.0138   \n",
       "1564       0.0153       0.0041       3.0590       0.0197       0.0086   \n",
       "1565       0.0178       0.0038       3.5662       0.0262       0.0245   \n",
       "1566       0.0181       0.0040       3.6275       0.0117       0.0162   \n",
       "\n",
       "      feature_589  feature_590  target_1             target_2  \n",
       "0             NaN          NaN        -1  19/07/2008 11:55:00  \n",
       "1          0.0060     208.2045        -1  19/07/2008 12:32:00  \n",
       "2          0.0148      82.8602         1  19/07/2008 13:17:00  \n",
       "3          0.0044      73.8432        -1  19/07/2008 14:43:00  \n",
       "4          0.0044      73.8432        -1  19/07/2008 15:22:00  \n",
       "...           ...          ...       ...                  ...  \n",
       "1562       0.0047     203.1720        -1  16/10/2008 15:13:00  \n",
       "1563       0.0047     203.1720        -1  16/10/2008 20:49:00  \n",
       "1564       0.0025      43.5231        -1  17/10/2008 05:26:00  \n",
       "1565       0.0075      93.4941        -1  17/10/2008 06:01:00  \n",
       "1566       0.0045     137.7844        -1  17/10/2008 06:07:00  \n",
       "\n",
       "[1567 rows x 592 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining data and creating proper structure of table\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Loading dataset \n",
    "try:\n",
    "    secom_data = pd.read_csv('C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom.data', delim_whitespace=True, header=None)\n",
    "    labels = pd.read_csv('C:/Users/Prajakta B/Desktop/SECOM_DATA/secom/secom_labels.data', delim_whitespace=True, header=None)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please verify file paths and names.\")\n",
    "    exit()\n",
    "    \n",
    "\n",
    "# # Combine features and labels \n",
    "df = pd.concat([secom_data, labels], axis=1)\n",
    "\n",
    "\n",
    "# # Rename columns like feature_1,2.. target_1,2..\n",
    "num_sensors = secom_data.shape[1]  # Number of sensor columns\n",
    "num_labels = labels.shape[1]       # Number of label columns\n",
    "new_columns = [f'feature_{i+1}' for i in range(num_sensors)] + [f'target_{i+1}' for i in range(num_labels)]\n",
    "df.columns = new_columns\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Analysis Report:\n",
      "Total Rows: 1567\n",
      "Duplicated Count: 0\n",
      "Duplicated Percentage: 0.0\n",
      "Duplicates With Same Label: 0\n",
      "Complete Duplicates: 0\n",
      "\n",
      "No duplicate rows found\n"
     ]
    }
   ],
   "source": [
    "# DESCRIPTIVE ANALYSIS - DUPLICATE DATA\n",
    "import pandas as pd\n",
    "\n",
    "# Duplicate row analysis\n",
    "duplicate_mask = df.duplicated(keep=False)  # Mark all duplicates\n",
    "duplicate_stats = {\n",
    "    'total_rows': len(df),\n",
    "    'duplicated_count': df.duplicated().sum(),\n",
    "    'duplicated_percentage': (df.duplicated().mean() * 100).round(2),\n",
    "   'duplicates_with_same_label': df.loc[df.duplicated(), new_columns[-1]].nunique(),\n",
    "    'complete_duplicates': duplicate_mask.sum()\n",
    "}\n",
    "\n",
    "# # Key statistic values\n",
    "print(\"Duplicate Analysis Report\")\n",
    "for stat, value in duplicate_stats.items():\n",
    "    print(f\"{stat.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# # Result\n",
    "if duplicate_stats['duplicated_count'] > 0:\n",
    "    print(\"\\nSample Duplicate Rows:\")\n",
    "    duplicates = df[duplicate_mask].sort_values(by=list(df.columns))\n",
    "    # print(duplicates.head())\n",
    "else:\n",
    "    print(\"\\nNo duplicate rows found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91977289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics with Variance:\n",
      "\n",
      "Zero Volatility Columns:\n",
      "[5, 13, 42, 49, 52, 69, 97, 141, 149, 178, 179, 186, 189, 190, 191, 192, 193, 194, 226, 229, 230, 231, 232, 233, 234, 235, 236, 237, 240, 241, 242, 243, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 276, 284, 313, 314, 315, 322, 325, 326, 327, 328, 329, 330, 364, 369, 370, 371, 372, 373, 374, 375, 378, 379, 380, 381, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 414, 422, 449, 450, 451, 458, 461, 462, 463, 464, 465, 466, 481, 498, 501, 502, 503, 504, 505, 506, 507, 508, 509, 512, 513, 514, 515, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538]\n",
      "Count: 116\n",
      "Percentage: 19.66%\n"
     ]
    }
   ],
   "source": [
    "# Descriptive Analysis - Zero volatility columns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def descriptive_analysis_zero_volatility(df):\n",
    "\n",
    "    # Basic descriptive statistics\n",
    "    desc_stats = df.describe().T  \n",
    "    \n",
    "    # Add variance calculation\n",
    "    desc_stats['variance'] = df.var()\n",
    "    \n",
    "    # Identify zero-volatility columns (variance = 0)\n",
    "    zero_vol_cols = desc_stats[desc_stats['variance'] == 0].index.tolist()\n",
    "    \n",
    "    # Calculate percentage of zero-volatility columns\n",
    "    total_columns = df.shape[1]\n",
    "    zero_vol_count = len(zero_vol_cols)\n",
    "    zero_vol_percentage = (zero_vol_count / total_columns) * 100\n",
    "    \n",
    "    # Create summary report\n",
    "    report = {\n",
    "        # 'descriptive_stats': desc_stats,         # Full descriptive stats with variance\n",
    "        'zero_volatility_cols': zero_vol_cols,   # List of zero-volatility columns\n",
    "        'zero_volatility_count': zero_vol_count, # Count of zero-volatility columns\n",
    "        'zero_volatility_percentage': zero_vol_percentage  # Percentage of zero-volatility columns\n",
    "    }\n",
    "    \n",
    "    return report\n",
    "\n",
    "#function call\n",
    "analysis = descriptive_analysis_zero_volatility(secom_data)\n",
    "\n",
    "\n",
    "print(\"Descriptive Statistics with Variance:\")\n",
    "print(\"\\nZero Volatility Columns:\")\n",
    "print(analysis['zero_volatility_cols'])\n",
    "print(f\"Count: {analysis['zero_volatility_count']}\")\n",
    "print(f\"Percentage: {analysis['zero_volatility_percentage']:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c5c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlow_volatility_analysis\u001b[39m(df, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, max_hist\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Calculate variances\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     variances \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mvar()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#  Descriptive Analysis - Low volatility column analysis using histogram and pareto chart\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def low_volatility_analysis(df, threshold=0.01, max_hist=5):\n",
    "    \"\"\"\n",
    "    Descriptive analysis of low-volatility columns in a DataFrame using histograms and a Pareto chart.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with numeric columns.\n",
    "    - threshold (float): Proportion of max variance to define 'low volatility' (default 0.01 = 1%).\n",
    "    - max_hist (int): Maximum number of histograms to display (default 5).\n",
    "    \"\"\"\n",
    "    # Calculate variances for all columns\n",
    "    variances = df.var(numeric_only=True)\n",
    "    max_var = variances.max()\n",
    "    low_var_cols = variances[variances <= max_var * threshold].sort_values()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Low-volatility threshold: {max_var * threshold:.4g}\")\n",
    "    print(f\"Columns with low volatility: {len(low_var_cols)} / {df.shape[1]} \"\n",
    "          f\"({len(low_var_cols)/df.shape[1]*100:.2f}%)\")\n",
    "    print(\"Low-volatility columns:\", list(low_var_cols.index))\n",
    "    \n",
    "    # Plot histograms for up to max_hist low-volatility columns\n",
    "    for col in low_var_cols.index[:max_hist]:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        sns.histplot(df[col].dropna(), bins=30, kde=False, color='skyblue')\n",
    "        plt.title(f'Histogram: {col} (Var: {variances[col]:.4g})')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Pareto chart for low-volatility columns\n",
    "    if not low_var_cols.empty:\n",
    "        cum_pct = low_var_cols.cumsum() / low_var_cols.sum() * 100\n",
    "        fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "        ax1.bar(low_var_cols.index, low_var_cols.values, color='C0')\n",
    "        ax1.set_ylabel('Variance', color='C0')\n",
    "        ax1.tick_params(axis='y', labelcolor='C0')\n",
    "        ax1.set_xticklabels(low_var_cols.index, rotation=90)\n",
    "        \n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(low_var_cols.index, cum_pct, color='C1', marker='o')\n",
    "        ax2.set_ylabel('Cumulative %', color='C1')\n",
    "        ax2.tick_params(axis='y', labelcolor='C1')\n",
    "        \n",
    "        plt.title('Pareto Chart of Low-Volatility Columns')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# low_volatility_analysis(df)\n",
    "which python\n",
    "which pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Analysis - Missing values using histogram and pareto chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb1c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Analysis - Correlation heatmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
